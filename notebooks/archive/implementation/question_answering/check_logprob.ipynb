{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Teias\\Thesis\\self-explaination-thesis\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.display import display, HTML\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import os\n",
    "\n",
    "# Initialize the Cohere client with your API key\n",
    "co = cohere.ClientV2(api_key=os.getenv(\"COHERE_API_KEY\", \"k4nv2XHVUMI9IDp3R4TV5jyzax5DufqG1nZDh5up\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The capital of France is Paris.\n",
      "\n",
      "Token Log Probabilities:\n",
      "Token: 'The', Logprob: -1.3113031e-06\n",
      "Token: ' capital', Logprob: -0.00010538656\n",
      "Token: ' of', Logprob: -9.536748e-07\n",
      "Token: ' France', Logprob: -9.536748e-07\n",
      "Token: ' is', Logprob: -9.536748e-07\n",
      "Token: ' Paris', Logprob: -9.536748e-07\n",
      "Token: '.', Logprob: -9.536748e-07\n"
     ]
    }
   ],
   "source": [
    "# Define the Q&A task\n",
    "context = \"The capital of France is Paris, known for its art and culture.\"\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "# Send request to Cohere Chat API\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Context: {context}\n",
    "            Question: {question}\n",
    "            Provide the answer based on the context.\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    logprobs=True,  # Enable logprobs\n",
    "    temperature=0.3   # For deterministic output\n",
    ")\n",
    "\n",
    "# Extract the answer from the nested structure\n",
    "answer = response.message.content[0].text\n",
    "\n",
    "# Extract logprobs\n",
    "logprobs = response.logprobs\n",
    "\n",
    "# Print the results\n",
    "print(\"Answer:\", answer)\n",
    "print(\"\\nToken Log Probabilities:\")\n",
    "for item in logprobs:\n",
    "    print(f\"Token: '{item.text}', Logprob: {item.logprobs[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-confidence tokens for reinforcement: [('The', -1.3113031e-06), (' capital', -0.00010538656), (' of', -9.536748e-07), (' France', -9.536748e-07), (' is', -9.536748e-07), (' Paris', -9.536748e-07), ('.', -9.536748e-07)]\n"
     ]
    }
   ],
   "source": [
    "high_confidence_tokens = [(item.text, item.logprobs[0]) for item in logprobs if item.logprobs[0] > -0.1]\n",
    "print(\"High-confidence tokens for reinforcement:\", high_confidence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Initialize Cohere client\n",
    "co = cohere.Client(api_key=\"your-api-key-here\")\n",
    "\n",
    "# Helper function to get response and extract answer/logprobs\n",
    "def get_response(prompt: str, include_explanation: bool = True) -> Tuple[str, List[float], List[str]]:\n",
    "    \"\"\"Generate a response with or without explanation and return answer, answer logprobs, and tokens.\"\"\"\n",
    "    if include_explanation:\n",
    "        full_prompt = f\"\"\"\n",
    "        {prompt}\n",
    "        Provide the answer based on the context, followed by a step-by-step explanation.\n",
    "        Format your response as:\n",
    "        Answer: [your answer]\n",
    "        Explanation: [step-by-step reasoning]\n",
    "        \"\"\"\n",
    "    else:\n",
    "        full_prompt = f\"\"\"\n",
    "        {prompt}\n",
    "        Provide only the answer based on the context.\n",
    "        Format your response as:\n",
    "        Answer: [your answer]\n",
    "        \"\"\"\n",
    "\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=[{\"role\": \"user\", \"content\": full_prompt}],\n",
    "        logprobs=True,\n",
    "        temperature=0  # Deterministic output\n",
    "    )\n",
    "\n",
    "    # Extract full text and logprobs\n",
    "    full_text = response.message.content[0].text\n",
    "    logprobs = [item.logprobs[0] for item in response.logprobs]\n",
    "    tokens = [item.text for item in response.logprobs]\n",
    "\n",
    "    # Extract answer\n",
    "    answer_start = full_text.index(\"Answer:\") + len(\"Answer:\")\n",
    "    if include_explanation:\n",
    "        answer_end = full_text.index(\"Explanation:\")\n",
    "        answer = full_text[answer_start:answer_end].strip()\n",
    "    else:\n",
    "        answer = full_text[answer_start:].strip()\n",
    "\n",
    "    # Approximate logprobs for answer tokens\n",
    "    answer_tokens = answer.split()\n",
    "    answer_start_idx = next(i for i, token in enumerate(tokens) if token.startswith(answer_tokens[0]))\n",
    "    answer_logprobs = logprobs[answer_start_idx:answer_start_idx + len(answer_tokens)]\n",
    "\n",
    "    return answer, answer_logprobs, tokens\n",
    "\n",
    "# 1. Conditional Answer Confidence (CAC)\n",
    "def compute_cac(context: str, question: str) -> float:\n",
    "    \"\"\"Calculate the average logprob of answer tokens given question and explanation.\"\"\"\n",
    "    prompt = f\"Context: {context}\\nQuestion: {question}\"\n",
    "    _, answer_logprobs, _ = get_response(prompt, include_explanation=True)\n",
    "    cac = np.mean(answer_logprobs)\n",
    "    return cac\n",
    "\n",
    "# 2. Explanation Boost (EB)\n",
    "def compute_eb(context: str, question: str) -> float:\n",
    "    \"\"\"Measure the boost in answer confidence due to the explanation.\"\"\"\n",
    "    prompt = f\"Context: {context}\\nQuestion: {question}\"\n",
    "    # With explanation\n",
    "    _, answer_logprobs_with_e, _ = get_response(prompt, include_explanation=True)\n",
    "    cac_with_e = np.mean(answer_logprobs_with_e)\n",
    "    # Without explanation\n",
    "    _, answer_logprobs_without_e, _ = get_response(prompt, include_explanation=False)\n",
    "    cac_without_e = np.mean(answer_logprobs_without_e)\n",
    "    eb = cac_with_e - cac_without_e\n",
    "    return eb\n",
    "\n",
    "# 3. Confidence Coverage (CC)\n",
    "def compute_cc(context: str, question: str, threshold: float = -0.1) -> float:\n",
    "    \"\"\"Calculate the percentage of explanation tokens above a logprob threshold.\"\"\"\n",
    "    prompt = f\"Context: {context}\\nQuestion: {question}\"\n",
    "    full_text, answer_logprobs, tokens = get_response(prompt, include_explanation=True)\n",
    "    \n",
    "    # Extract explanation part\n",
    "    explanation_start = full_text.index(\"Explanation:\") + len(\"Explanation:\")\n",
    "    explanation_text = full_text[explanation_start:].strip()\n",
    "    explanation_tokens = explanation_text.split()\n",
    "    \n",
    "    # Find the start index of explanation in tokens\n",
    "    explanation_start_idx = next(i for i, token in enumerate(tokens) if token.startswith(explanation_tokens[0]))\n",
    "    explanation_logprobs = answer_logprobs[explanation_start_idx:explanation_start_idx + len(explanation_tokens)]\n",
    "    \n",
    "    # Count tokens above threshold\n",
    "    high_confidence_count = sum(1 for lp in explanation_logprobs if lp > threshold)\n",
    "    cc = (high_confidence_count / len(explanation_logprobs)) * 100 if explanation_logprobs else 0\n",
    "    return cc\n",
    "\n",
    "# 4. Perturbation Sensitivity (PS)\n",
    "def compute_ps(context: str, question: str, perturbation_index: int = 1) -> float:\n",
    "    \"\"\"Measure the change in CAC after perturbing an explanation token.\"\"\"\n",
    "    prompt = f\"Context: {context}\\nQuestion: {question}\"\n",
    "    \n",
    "    # Original response\n",
    "    original_answer, original_logprobs, original_tokens = get_response(prompt, include_explanation=True)\n",
    "    original_cac = np.mean(original_logprobs)\n",
    "    \n",
    "    # Extract explanation\n",
    "    full_text = response.message.content[0].text\n",
    "    explanation_start = full_text.index(\"Explanation:\") + len(\"Explanation:\")\n",
    "    explanation_text = full_text[explanation_start:].strip()\n",
    "    explanation_tokens = explanation_text.split()\n",
    "    \n",
    "    # Perturb one token\n",
    "    if perturbation_index < len(explanation_tokens):\n",
    "        explanation_tokens[perturbation_index] = \"ERROR\"  # Simple perturbation\n",
    "    perturbed_explanation = \" \".join(explanation_tokens)\n",
    "    \n",
    "    # Regenerate with perturbed explanation\n",
    "    perturbed_prompt = f\"\"\"\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Provide the answer based on this explanation:\n",
    "    Answer: {original_answer}\n",
    "    Explanation: {perturbed_explanation}\n",
    "    \"\"\"\n",
    "    perturbed_response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=[{\"role\": \"user\", \"content\": perturbed_prompt}],\n",
    "        logprobs=True,\n",
    "        temperature=0\n",
    "    )\n",
    "    perturbed_text = perturbed_response.message.content[0].text\n",
    "    perturbed_logprobs = [item.logprobs[0] for item in perturbed_response.logprobs]\n",
    "    perturbed_answer_start = perturbed_text.index(\"Answer:\") + len(\"Answer:\")\n",
    "    perturbed_answer_end = perturbed_text.index(\"Explanation:\")\n",
    "    perturbed_answer = perturbed_text[perturbed_answer_start:perturbed_answer_end].strip()\n",
    "    perturbed_answer_tokens = perturbed_answer.split()\n",
    "    perturbed_start_idx = next(i for i, token in enumerate([item.text for item in perturbed_response.logprobs]) if token.startswith(perturbed_answer_tokens[0]))\n",
    "    perturbed_answer_logprobs = perturbed_logprobs[perturbed_start_idx:perturbed_start_idx + len(perturbed_answer_tokens)]\n",
    "    perturbed_cac = np.mean(perturbed_answer_logprobs)\n",
    "    \n",
    "    # Calculate PS as the absolute difference in CAC\n",
    "    ps = abs(original_cac - perturbed_cac)\n",
    "    return ps\n",
    "\n",
    "# Example usage\n",
    "context = \"The capital of France is Paris, known for its art and culture.\"\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "cac = compute_cac(context, question)\n",
    "eb = compute_eb(context, question)\n",
    "cc = compute_cc(context, question, threshold=-0.1)\n",
    "ps = compute_ps(context, question, perturbation_index=1)\n",
    "\n",
    "print(f\"Conditional Answer Confidence (CAC): {cac:.4f}\")\n",
    "print(f\"Explanation Boost (EB): {eb:.4f}\")\n",
    "print(f\"Confidence Coverage (CC): {cc:.2f}%\")\n",
    "print(f\"Perturbation Sensitivity (PS): {ps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer and Explanation:\n",
      "C. Water storage.\n"
     ]
    }
   ],
   "source": [
    "# Define the input components\n",
    "context = (\"In a desert ecosystem, water is scarce and animals have adapted by storing water \"\n",
    "           \"for long periods.\")\n",
    "question = \"What adaptation helps animals survive in the desert?\"\n",
    "options = \"A. Growing larger; B. Hibernation; C. Water storage; D. Migration\"\n",
    "\n",
    "# Prepare a prompt that asks the model to both answer and explain its answer\n",
    "prompt = f\"\"\"{context}\n",
    "Question: {question}\n",
    "Options: {options}\n",
    "Answer and Explanation:\"\"\"\n",
    "\n",
    "# Generate the answer using Cohere's generation API\n",
    "response = co.generate(\n",
    "    model='command-r-plus-08-2024',  # or choose a model available in your account\n",
    "    prompt=prompt,\n",
    "    max_tokens=100,\n",
    "    temperature=0.5,\n",
    "    k=0,\n",
    "    p=0.75,\n",
    "    stop_sequences=[\"\\n\"]\n",
    ")\n",
    "\n",
    "# Output the generated text\n",
    "generated_text = response.generations[0].text.strip()\n",
    "print(\"Generated Answer and Explanation:\")\n",
    "print(generated_text)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Pseudo-code for extracting log probabilities (if supported):\n",
    "#\n",
    "# Note: As of now, Cohere's API may not return token-level log probabilities directly.\n",
    "# If such functionality becomes available, the code might look like this:\n",
    "#\n",
    "# response_with_logprobs = co.generate(\n",
    "#     model='command-xlarge-nightly',\n",
    "#     prompt=prompt,\n",
    "#     max_tokens=100,\n",
    "#     temperature=0.5,\n",
    "#     k=0,\n",
    "#     p=0.75,\n",
    "#     stop_sequences=[\"\\n\"],\n",
    "#     return_likelihoods='ALL'  # hypothetical parameter for log probabilities\n",
    "# )\n",
    "#\n",
    "# # Access token-level log probabilities:\n",
    "# tokens = response_with_logprobs.generations[0].tokens\n",
    "# log_probs = response_with_logprobs.generations[0].logprobs\n",
    "#\n",
    "# for token, lp in zip(tokens, log_probs):\n",
    "#     print(f\"Token: {token}, Log Probability: {lp}\")\n",
    "#\n",
    "# You can then analyze these log probabilities to see if higher values correlate with more\n",
    "# faithful explanations.\n",
    "# --------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer and Explanation:\n",
      "Answer: C. Water storage. \n",
      "\n",
      "Explanation: Animals in desert ecosystems have adapted to the scarcity of water by evolving mechanisms to store water for extended periods, helping them survive in arid conditions. This adaptation allows them to conserve and utilize water efficiently, ensuring their survival in an environment with limited water resources.\n",
      "\n",
      "Token Log Probabilities:\n",
      "Token: 'Answer', Logprob: -0.00010538656\n",
      "Token: ':', Logprob: -9.536748e-07\n",
      "Token: ' C', Logprob: -0.03528582\n",
      "Token: '.', Logprob: -9.536748e-07\n",
      "Token: ' Water', Logprob: -9.536748e-07\n",
      "Token: ' storage', Logprob: -9.536748e-07\n",
      "Token: '.', Logprob: -0.004193204\n",
      "Token: ' \n",
      "\n",
      "Explanation', Logprob: -9.536748e-07\n",
      "Token: ':', Logprob: -9.536748e-07\n",
      "Token: ' Animals', Logprob: -1.243127\n",
      "Token: ' in', Logprob: -0.015454063\n",
      "Token: ' desert', Logprob: -2.6226078e-06\n",
      "Token: ' ecosystems', Logprob: -9.536748e-07\n",
      "Token: ' have', Logprob: -0.117353566\n",
      "Token: ' adapted', Logprob: -9.536789e-06\n",
      "Token: ' to', Logprob: -9.536748e-07\n",
      "Token: ' the', Logprob: -1.0728842e-06\n",
      "Token: ' scarcity', Logprob: -0.03814185\n",
      "Token: ' of', Logprob: -9.536748e-07\n",
      "Token: ' water', Logprob: -9.536748e-07\n",
      "Token: ' by', Logprob: -9.536748e-07\n",
      "Token: ' evolving', Logprob: -0.17301038\n",
      "Token: ' mechanisms', Logprob: -0.0008494885\n",
      "Token: ' to', Logprob: -9.536748e-07\n",
      "Token: ' store', Logprob: -9.536748e-07\n",
      "Token: ' water', Logprob: -9.536748e-07\n",
      "Token: ' for', Logprob: -9.536748e-07\n",
      "Token: ' extended', Logprob: -3.4570753e-06\n",
      "Token: ' periods', Logprob: -9.536748e-07\n",
      "Token: ',', Logprob: -0.07889063\n",
      "Token: ' helping', Logprob: -0.23300223\n",
      "Token: ' them', Logprob: -9.536748e-07\n",
      "Token: ' survive', Logprob: -9.536748e-07\n",
      "Token: ' in', Logprob: -1.3113031e-06\n",
      "Token: ' arid', Logprob: -0.0044783344\n",
      "Token: ' conditions', Logprob: -9.536748e-07\n",
      "Token: '.', Logprob: -0.0012728324\n",
      "Token: ' This', Logprob: -0.17330493\n",
      "Token: ' adaptation', Logprob: -0.0032933285\n",
      "Token: ' allows', Logprob: -0.0019335952\n",
      "Token: ' them', Logprob: -9.536748e-07\n",
      "Token: ' to', Logprob: -9.536748e-07\n",
      "Token: ' conserve', Logprob: -0.544142\n",
      "Token: ' and', Logprob: -0.00015939552\n",
      "Token: ' utilize', Logprob: -4.637349e-05\n",
      "Token: ' water', Logprob: -9.536748e-07\n",
      "Token: ' efficiently', Logprob: -9.536748e-07\n",
      "Token: ',', Logprob: -0.00024136834\n",
      "Token: ' ensuring', Logprob: -0.002780963\n",
      "Token: ' their', Logprob: -9.536748e-07\n",
      "Token: ' survival', Logprob: -1.0728842e-06\n",
      "Token: ' in', Logprob: -0.008528977\n",
      "Token: ' an', Logprob: -0.0012813668\n",
      "Token: ' environment', Logprob: -9.536748e-07\n",
      "Token: ' with', Logprob: -2.0742631e-05\n",
      "Token: ' limited', Logprob: -9.536748e-07\n",
      "Token: ' water', Logprob: -9.536748e-07\n",
      "Token: ' resources', Logprob: -2.133869e-05\n",
      "Token: '.', Logprob: -9.536748e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the input components for the Q&A task\n",
    "context = (\"In a desert ecosystem, water is scarce and animals have adapted by storing water \"\n",
    "           \"for long periods.\")\n",
    "question = \"What adaptation helps animals survive in the desert?\"\n",
    "options = \"A. Growing larger; B. Hibernation; C. Water storage; D. Migration\"\n",
    "\n",
    "# Construct the prompt\n",
    "prompt = f\"\"\"{context}\n",
    "Question: {question}\n",
    "Options: {options}\n",
    "Answer and Explanation:\"\"\"\n",
    "\n",
    "# Generate the answer with log probabilities enabled\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    logprobs=True,  # Enable log probabilities for faithfulness analysis\n",
    "    temperature=0.3  # Low temperature for deterministic output\n",
    ")\n",
    "\n",
    "# Extract the generated answer and explanation\n",
    "answer = response.message.content[0].text\n",
    "\n",
    "# Extract token-level log probabilities\n",
    "logprobs = response.logprobs\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated Answer and Explanation:\")\n",
    "print(answer)\n",
    "\n",
    "# Print token log probabilities\n",
    "print(\"\\nToken Log Probabilities:\")\n",
    "for item in logprobs:\n",
    "    print(f\"Token: '{item.text}', Logprob: {item.logprobs[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: اردبیل\n",
      "\n",
      "Token Log Probabilities:\n",
      "Token: 'ارد', Logprob: -0.5063616\n",
      "Token: 'ب', Logprob: -9.536748e-07\n",
      "Token: 'یل', Logprob: -9.536748e-07\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Persian Q&A task\n",
    "context = \"ایران کشوری در خاورمیانه است و پایتخت آن اردبیل می‌باشد.\"\n",
    "question = \"پایتخت ایران کجاست؟\"\n",
    "\n",
    "# Send request to Cohere Chat API\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Context: {context}\n",
    "            Question: {question}\n",
    "            Provide the answer based on the context.\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    logprobs=True,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# Extract answer\n",
    "answer = response.message.content[0].text\n",
    "\n",
    "# Extract log probabilities\n",
    "logprobs = response.logprobs\n",
    "\n",
    "# Extract tokens and log probabilities\n",
    "tokens = [item.text for item in logprobs]\n",
    "log_prob_values = [item.logprobs[0] for item in logprobs]\n",
    "\n",
    "# Plot the log probabilities\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.barh(tokens, log_prob_values, color='skyblue')\n",
    "plt.xlabel(\"Log Probability\")\n",
    "plt.ylabel(\"Tokens\")\n",
    "plt.title(\"Token Log Probabilities for Persian QA\")\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"Answer:\", answer)\n",
    "print(\"\\nToken Log Probabilities:\")\n",
    "for token, logprob in zip(tokens, log_prob_values):\n",
    "    print(f\"Token: '{token}', Logprob: {logprob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogprobItem(text='پ', token_ids=[4249], logprobs=[-0.023252217]),\n",
       " LogprobItem(text='ایت', token_ids=[39903], logprobs=[-2.6226078e-06]),\n",
       " LogprobItem(text='خت', token_ids=[20634], logprobs=[-9.536748e-07]),\n",
       " LogprobItem(text=' ایران', token_ids=[17750], logprobs=[-9.536748e-07]),\n",
       " LogprobItem(text=' تهران', token_ids=[57639], logprobs=[-0.36088815]),\n",
       " LogprobItem(text=' است', token_ids=[6079], logprobs=[-9.536748e-07]),\n",
       " LogprobItem(text='.', token_ids=[21], logprobs=[-0.00010538656])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
